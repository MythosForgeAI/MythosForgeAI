<script>
        const chatOutput = document.getElementById('chat-output');
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-button');

        // Initialize conversation history. 
        // The first "model" message is just for display on the page load.
        // The actual history sent to the AI will build up from user interactions.
        let conversationHistory = [
            { 
                role: "model", // This is for Gemini's format
                parts: [{ text: "Hello Kyle! I'm your MythosForgeAI prototype. Send a message to test the live API!" }] 
            }
        ];

        // Display the initial AI message (if you want it to appear from the start)
        // If you remove the initial message above from conversationHistory, also remove this call.
        // displayMessage(conversationHistory[0].parts[0].text, 'AI'); 

        /**
         * Displays a message in the chat output area.
         * @param {string} message - The message text.
         * @param {string} sender - "User" or "AI".
         */
        function displayMessage(message, sender) {
            const messageElement = document.createElement('div');
            messageElement.classList.add('chat-bubble');
            if (sender === 'User') {
                messageElement.classList.add('user-bubble');
                messageElement.textContent = `You: ${message}`;
            } else {
                messageElement.classList.add('ai-bubble');
                messageElement.textContent = `AI: ${message}`;
            }
            chatOutput.appendChild(messageElement);
            chatOutput.scrollTop = chatOutput.scrollHeight; // Auto-scroll to bottom
        }

        /**
         * Gets a response from the AI via your Netlify backend proxy.
         * @param {string} userMessageText - The user's message text.
         */
        async function getAIResponse(userMessageText) {
            // Add the current user's message to the conversation history
            // This ensures the history sent to the proxy includes the latest message
            conversationHistory.push({ role: "user", parts: [{ text: userMessageText }] });

            // This is the URL of YOUR Netlify function that you deployed
            const yourNetlifyProxyUrl = "https://mythosforgeai.com/.netlify/functions/llm-proxy"; 

            console.log("Attempting to send to Netlify proxy:", yourNetlifyProxyUrl);
            console.log("Sending conversation history:", JSON.stringify(conversationHistory, null, 2));

            let aiResponseText = "Error: Could not reach the AI service. Please check console."; // Default error

            try {
                // This is the data we send TO YOUR NETLIFY FUNCTION
                // Your Netlify function expects an object with a "history" key
                const payloadToProxy = {
                    history: conversationHistory
                };

                const response = await fetch(yourNetlifyProxyUrl, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify(payloadToProxy)
                });

                if (!response.ok) {
                    // If the response status is not OK (e.g., 4xx, 5xx)
                    const errorData = await response.json(); // Try to parse error from proxy
                    console.error(`Error from proxy (Status ${response.status}):`, errorData);
                    aiResponseText = `Error: ${errorData.error || `Request to AI service failed (${response.status})`}`;
                } else {
                    // If the response is OK, parse the JSON
                    const result = await response.json(); 
                    if (result.aiMessage) {
                        aiResponseText = result.aiMessage;
                    } else if (result.error) {
                        console.error("Error message from proxy function:", result.error);
                        aiResponseText = `Error from AI service: ${result.error}`;
                    } else {
                        // If the proxy returns success (200) but not the expected JSON format
                        console.error("Unexpected response structure from proxy:", result);
                        aiResponseText = "Received an unexpected response from the AI service.";
                    }
                }

            } catch (error) {
                // This catches network errors (e.g., proxy URL is wrong, Netlify function not found, CORS if misconfigured)
                console.error("Network or fetch error calling your backend proxy:", error);
                aiResponseText = "Network error or proxy is unreachable. Please check console and Netlify function logs.";
            }
            
            // Add the AI's response to our conversation history for the next turn
            if (aiResponseText) { // Ensure we have some response text
                conversationHistory.push({ role: "model", parts: [{ text: aiResponseText }] });
            }
            
            // Limit history size (basic trimming to prevent overly large payloads)
            const maxHistoryTurns = 10; // Keep last 10 turns (1 turn = 1 user message + 1 AI message)
            const maxHistoryItems = maxHistoryTurns * 2; 
            if (conversationHistory.length > maxHistoryItems) {
                // Slice from the end to keep the most recent items
                conversationHistory = conversationHistory.slice(conversationHistory.length - maxHistoryItems);
            }

            // Display the AI's final response (or error message)
            if (aiResponseText) {
                 displayMessage(aiResponseText, 'AI');
            }
        }

        /**
         * Handles sending the user's message.
         */
        function handleSendMessage() {
            const messageText = messageInput.value.trim();
            if (messageText) {
                displayMessage(messageText, 'User'); // Display user message immediately
                messageInput.value = ''; // Clear input field
                getAIResponse(messageText); // Then get AI response
            }
        }

        sendButton.addEventListener('click', handleSendMessage);
        messageInput.addEventListener('keypress', function(event) {
            if (event.key === 'Enter') {
                handleSendMessage();
            }
        });

        // Optional: If you don't want the initial AI message to be part of the history sent on the *first* user message,
        // you can display it and then clear or re-initialize conversationHistory for the actual interaction.
        // For now, the initial AI message is part of the history array.
        // If you prefer to display the first AI message without it being in history, do this:
        // displayMessage("Hello Kyle! I'm your MythosForgeAI prototype. Send a message to test the live API!", 'AI');
        // conversationHistory = []; // Start with an empty history for API calls

    </script>
</body>
</html>
